{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import data and libraries necessary:",
   "id": "1d6c2b3f0e09d3ac"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T13:03:47.393926Z",
     "start_time": "2025-12-10T13:03:46.325710Z"
    }
   },
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sys\n",
    "import re\n",
    "\n",
    "# Download NLTK resources (only needs to be run once)\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "sys.path.append('..')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:03:47.900005Z",
     "start_time": "2025-12-10T13:03:47.393926Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(\"../data/MN-DS-news-classification.csv\")",
   "id": "de2cfede71b805fc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Find missing values:",
   "id": "1a998b25dfd51d1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:03:47.926579Z",
     "start_time": "2025-12-10T13:03:47.908867Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "bf0b3ca48921c113",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10917 entries, 0 to 10916\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   data_id           10917 non-null  int64 \n",
      " 1   id                10917 non-null  object\n",
      " 2   date              10917 non-null  object\n",
      " 3   source            10917 non-null  object\n",
      " 4   title             10917 non-null  object\n",
      " 5   content           10917 non-null  object\n",
      " 6   author            7605 non-null   object\n",
      " 7   url               10917 non-null  object\n",
      " 8   published         10917 non-null  object\n",
      " 9   published_utc     10917 non-null  int64 \n",
      " 10  collection_utc    10917 non-null  int64 \n",
      " 11  category_level_1  10917 non-null  object\n",
      " 12  category_level_2  10917 non-null  object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:03:47.955648Z",
     "start_time": "2025-12-10T13:03:47.934619Z"
    }
   },
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "id": "40d4613182058f36",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_id                0\n",
       "id                     0\n",
       "date                   0\n",
       "source                 0\n",
       "title                  0\n",
       "content                0\n",
       "author              3312\n",
       "url                    0\n",
       "published              0\n",
       "published_utc          0\n",
       "collection_utc         0\n",
       "category_level_1       0\n",
       "category_level_2       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Feature Selection:\n",
    "\n",
    "### Strategy:\n",
    "We will select only the columns relevant for text classification and remove metadata or unbalanced features.\n",
    "\n",
    "Columns:\n",
    "- `author` the author's name doesn't define the subject of the news  (REMOVE)\n",
    "- `data_id, id` are just unique identifiers  (REMOVE)\n",
    "- `date, published, published_utc, collection_utc` are temporal data. It doesn't help us classify the text (REMOVE)\n",
    "- `url` Does not contain useful information for the model  (REMOVE)\n",
    "- `source` the model reads the text to make a prediction, not its source (REMOVE)\n",
    "- `category_level_2` too many classes. 17 categories at Level 1 (Manageable, robust) in Level 2 there are 109 sub-categories. It is much harder for a model to hit 1 in 109 variants than 1 in 17. (REMOVE)"
   ],
   "id": "d2a9528d400248f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:03:48.010576Z",
     "start_time": "2025-12-10T13:03:48.002630Z"
    }
   },
   "cell_type": "code",
   "source": "df_final = df[['title', 'content', 'category_level_1']].copy()",
   "id": "7d2c5a5356363462",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:03:48.203816Z",
     "start_time": "2025-12-10T13:03:48.024597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check for duplicates based on text content\n",
    "initial_rows = df_final.shape[0]\n",
    "df_final = df_final.drop_duplicates(subset=['title', 'content'])\n",
    "rows_after_dedup = df_final.shape[0]\n",
    "\n",
    "print(f\"Initial rows: {initial_rows}\")\n",
    "print(f\"Duplicates removed: {initial_rows - rows_after_dedup}\")\n",
    "print(f\"Rows remaining for training: {rows_after_dedup}\")\n",
    "\n",
    "# Check the distribution of the target variable\n",
    "print(\"\\nTarget Class Distribution (Top 10):\")\n",
    "print(df_final['category_level_1'].value_counts().head(10))"
   ],
   "id": "239f11d994b7a359",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows: 10917\n",
      "Duplicates removed: 461\n",
      "Rows remaining for training: 10456\n",
      "\n",
      "Target Class Distribution (Top 10):\n",
      "category_level_1\n",
      "society                    1081\n",
      "politics                    887\n",
      "sport                       882\n",
      "conflict, war and peace     793\n",
      "science and technology      766\n",
      "religion and belief         755\n",
      "health                      686\n",
      "labour                      587\n",
      "environment                 579\n",
      "human interest              578\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Text Preprocessing:\n",
    "We apply advanced text cleaning to prepare the data for the TF-IDF vectorizer.\n",
    "\n",
    "**Techniques applied:**\n",
    "1.  **Lowercasing:** To ensure consistency (e.g., \"Apple\" == \"apple\").\n",
    "2.  **Regex Cleaning:** Keeping only letters (a-z), removing numbers and punctuation.\n",
    "3.  **Stopwords Removal:** Removing common words (e.g., \"the\", \"is\") that add noise.\n",
    "4.  **Lemmatization:** Reducing words to their root form (e.g., \"running\" -> \"run\") to reduce dimensionality and prevent overfitting."
   ],
   "id": "f366464433e8b1db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:03:48.272160Z",
     "start_time": "2025-12-10T13:03:48.250808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize NLP tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ],
   "id": "5c8590ff6fa63a32",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:03:48.387412Z",
     "start_time": "2025-12-10T13:03:48.378618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def advanced_clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by removing special characters, stopwords,\n",
    "    and applying lemmatization.\n",
    "    \"\"\"\n",
    "\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # Keep only letters (remove digits and punctuation)\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "\n",
    "    # Tokenize (split into words)\n",
    "    words = text.split()\n",
    "\n",
    "    # Remove stopwords and apply lemmatization\n",
    "    clean_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "    # Join back into a single string\n",
    "    text = ' '.join(clean_words)\n",
    "\n",
    "    return text"
   ],
   "id": "eda7aee8b8939d59",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:04:05.880619Z",
     "start_time": "2025-12-10T13:03:48.474014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine Title and Content for the model\n",
    "df_final['raw_text'] = df_final['title'] + \" \" + df_final['content']\n",
    "\n",
    "# Apply the cleaning function (This may take a moment)\n",
    "print(\"Processing text (Lemmatization & Stopwords)...\")\n",
    "df_final['clean_text'] = df_final['raw_text'].apply(advanced_clean_text)"
   ],
   "id": "e22588554b53e911",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text (Lemmatization & Stopwords)...\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save new data clean:",
   "id": "12284a1f54eb66ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:04:06.526724Z",
     "start_time": "2025-12-10T13:04:05.981468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_final[['title', 'clean_text', 'category_level_1']].to_csv(\n",
    "    \"../data/news_data_preprocessed_final.csv\",\n",
    "    index=False\n",
    ")"
   ],
   "id": "3165c31d0da17ff5",
   "outputs": [],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
